{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fa4aae-a839-4474-bda7-f741a349a249",
   "metadata": {},
   "source": [
    "# Automatic Diagnostics Report Generator using Small Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba56e2-5592-42e3-a6a4-60df69c84150",
   "metadata": {},
   "source": [
    "Automated Diagnostics Report Generator for VSB Power Line Fault Detection, uses open-source language models to generate intelligent analysis reports.\n",
    "Generates professional PDF reports for power grid operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863f0df3-3205-434d-b911-3520ccb78c1b",
   "metadata": {},
   "source": [
    "Model Predictions and Interpretations, Trend Analysis, Visualizations and Alerts can be added integrated with the “explanations carefully generated” using Small Language model like __HuggingFace Microsoft DialoGPT-small__ , __ollama__ or __GPT-2 variants__. It can be scheduled to be generated in cloud connected to the grid in regular intervals and pushed to a dashboard or sent to emails. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c4eb4-f1b3-4943-91f4-cb2d9268d7a3",
   "metadata": {},
   "source": [
    "## Value Proposition for Automatic Diagnostics Report Generation:\n",
    "\n",
    "* Transforms raw ML predictions into actionable operational intelligence\n",
    "* Reduces manual analysis time from hours to minutes and consistent reporting\n",
    "* No external API dependencies, Template-based insights when SLM unavailable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd1d6aa-ddf4-45b9-a7b2-3db2fd459ca1",
   "metadata": {},
   "source": [
    "#### This is just showing art of the possible, but we can expand in different ways to make this output in the best way needed by the stakeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73b00437-152d-4a35-9013-971075acd30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For PDF generation\n",
    "try:\n",
    "    from reportlab.lib.pagesizes import letter, A4\n",
    "    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, TableStyle, PageBreak\n",
    "    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "    from reportlab.lib.units import inch\n",
    "    from reportlab.lib import colors\n",
    "    from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_JUSTIFY\n",
    "    from reportlab.graphics.shapes import Drawing, Rect\n",
    "    from reportlab.graphics.charts.linecharts import HorizontalLineChart\n",
    "    from reportlab.graphics.charts.barcharts import VerticalBarChart\n",
    "    REPORTLAB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    REPORTLAB_AVAILABLE = False\n",
    "    print(\"reportlab not available. Install with: pip install reportlab\")\n",
    "\n",
    "# For open-source language models\n",
    "try:\n",
    "    from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "    TRANSFORMERS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TRANSFORMERS_AVAILABLE = False\n",
    "    print(\"transformers not available. Install with: pip install transformers torch\")\n",
    "\n",
    "try:\n",
    "    import ollama\n",
    "    OLLAMA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    OLLAMA_AVAILABLE = False\n",
    "\n",
    "\n",
    "# Imports from Helper functions\n",
    "from helper.common import prepare_data,create_feature_tier_mapping\n",
    "from helper.load_save_model import load_saved_model\n",
    "from helper.report_generation import generate_diagnostics_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b8cbd0-41d9-4f95-9ebe-93779269ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r'./data/vsb-power-line-fault-detection/'\n",
    "FEATURE_PATH = r\"./features//\"\n",
    "CHUNK_SIZE = 1000\n",
    "SAMPLE_SIZE=1000\n",
    "BEST_MODEL_PATH= r'saved_models\\best_model_catboost_fast_20250928_173554.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d604d0-875e-471f-b357-b9eff81a11f3",
   "metadata": {},
   "source": [
    "### Prepare Data for Creating Dignostics Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26399fbd-d25f-4d6f-9ce5-8ab148416c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and prepare data with optimized features\n",
    "feature_df  = pd.read_parquet(f\"{FEATURE_PATH}/final_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff20af1a-b036-45a2-9bac-d2a6a70c9e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for model training...\n",
      "Feature matrix shape: (5000, 124)\n",
      "Target distribution:\n",
      "target\n",
      "0    0.9336\n",
      "1    0.0664\n",
      "Name: proportion, dtype: float64\n",
      "Training set: 3200 samples\n",
      "Validation set: 800 samples\n",
      "Test set: 1000 samples\n"
     ]
    }
   ],
   "source": [
    "data_splits = prepare_data(feature_df, target_col='target',random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa96492d-7893-4ed5-ab9c-8ab23d7e033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_splits['X_train'],data_splits['X_test'],data_splits['y_train'], data_splits['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773a75eb-50b3-44b3-8637-aa8d7ba9ade9",
   "metadata": {},
   "source": [
    "### Loading the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "915366e5-d38b-48d1-87ee-3e1df84924cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded model: saved_models\\best_model_catboost_fast_20250928_173554.pkl\n"
     ]
    }
   ],
   "source": [
    "model, metadata = load_saved_model(BEST_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8e4127-b0a0-4281-8e87-676e17c3d4f8",
   "metadata": {},
   "source": [
    "### Preparing the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8746720e-389e-47ee-b01a-98cdb5748d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "117409bd-5fef-496f-a9f7-90d965c22e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5f528fd-14f6-4b0f-900f-c10f2f950de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame({\n",
    "    'prediction': y_pred,      # Required: 0 or 1\n",
    "    'confidence': y_pred_proba[:,1],    # Optional but recommended\n",
    "    'actual': y_test        ,         # Optional, for performance evaluation,\n",
    "    'signal_id':X_test.index\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2551f6e3-98bc-4210-bf7f-b7b550eeda9b",
   "metadata": {},
   "source": [
    "### Report Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b95a67-8032-4e80-9360-bc2d6fc8a139",
   "metadata": {},
   "source": [
    "#### Calling the report generation Helper Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d9690-d84d-4487-9920-15c556dc91c9",
   "metadata": {},
   "source": [
    "##### Uses __Microsoft SLM DialoGPT-small__ for report preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97092ddf-c1f4-49af-b87d-dab9c08c8168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data trends...\n",
      "No timestamp column found. Creating synthetic timestamps for analysis...\n",
      "Setting up huggingface language model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded Hugging Face model: microsoft/DialoGPT-small\n",
      "Generating insights...\n",
      "Error generating LLM insights: Input length of input_ids is 240, but `max_length` is set to 240. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.\n",
      "Creating visualizations...\n",
      "Generating PDF report...\n",
      "PDF report generated successfully: diagnostics_reports\\VSB_Diagnostics_Report_20250928_193620.pdf\n",
      "Diagnostics report generated successfully!\n",
      "Report: diagnostics_reports\\VSB_Diagnostics_Report_20250928_193620.pdf\n",
      "JSON Data: diagnostics_reports\\analysis_data_20250928_193620.json\n",
      "Visualizations: 2 plots saved\n",
      "Data source type: features\n"
     ]
    }
   ],
   "source": [
    "report_path = generate_diagnostics_report(\n",
    "    predictions_df=predictions_df,\n",
    "    output_format=\"pdf\",\n",
    "    data_source_type=\"features\"  # or \"auto\" for auto-detection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379dbfbf-1837-4e9e-a6b2-530c93e42cbb",
   "metadata": {},
   "source": [
    "#### This helper function is provided only for showcasing what is possible as a prototype. We make assumptions for timestamps, intervals and provide a template of report that shows the trends, anomalies and analysis results in a PDF report. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b789a2-c5de-4b79-9d8c-6525546232e8",
   "metadata": {},
   "source": [
    "### End of Automatic Diagnostics Report Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68431fb7-7440-4af4-bfae-514b3302830a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
